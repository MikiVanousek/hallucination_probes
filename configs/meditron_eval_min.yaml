probe_config:
  probe_id: meditron3_8b_lora_probe
  model_name: OpenMeditron/Meditron3-8B
  layer: 30
  threshold: 0.46
eval_datasets:
- dataset_id: llama3_1_8b_longform_test
  hf_repo: obalcells/longfact-annotations
  subset: Meta-Llama-3.1-8B-Instruct
  split: test
  max_length: 1536
  pos_weight: 10.0
  neg_weight: 1.0
  default_ignore: false
  shuffle: false
- dataset_id: llama3_1_8b_longform_augmented_test
  hf_repo: obalcells/longfact-augmented-annotations
  subset: Meta-Llama-3.1-8B-Instruct
  split: test
  max_length: 1536
  pos_weight: 10.0
  neg_weight: 1.0
  default_ignore: false
  shuffle: false
- dataset_id: llama3_1_8b_trivia_qa_test
  hf_repo: obalcells/triviaqa-balanced
  subset: Meta-Llama-3.1-8B-Instruct
  split: test
  max_length: 128
  pos_weight: 10.0
  neg_weight: 1.0
  default_ignore: false
  shuffle: false
- dataset_id: llama3_1_8b_healthbench_test
  hf_repo: obalcells/healthbench-annotations
  subset: Meta-Llama-3.1-8B-Instruct
  split: test
  max_length: 1536
  pos_weight: 1.0
  neg_weight: 1.0
  default_ignore: false
  shuffle: false
save_evaluation_metrics: true
save_roc_curves: false
dump_raw_eval_results: false
